{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('WaterPumpData/features_train.csv')\n",
    "y_train = pd.read_csv('WaterPumpData/labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['label'] = y_train.status_group.apply(lambda x: 1 if x == 'functional' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "funder = x_train.funder.str.lower().value_counts()\n",
    "funder = funder[funder > 250]\n",
    "x_train['funder_mod'] = [i if i in funder else 'Unknown' for i in x_train.funder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample\n",
    "\n",
    "validation_set = sample(list(x_train.id), len(x_train)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def create_randomforest_model(feature_set, cat_var):\n",
    "    categorical_bool = [True if i in cat_var else False for i in feature_set]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    xx_train = pd.get_dummies(x_train[feature_set], columns=cat_var)\n",
    "    xxx_train = xx_train.loc[~x_train.id.isin(validation_set)]\n",
    "    xxx_validate = xx_train.loc[x_train.id.isin(validation_set)]\n",
    "    yy_train = y_train.loc[~y_train.id.isin(validation_set)].label\n",
    "    yy_validate = y_train.loc[y_train.id.isin(validation_set)].label\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(xxx_train, yy_train)\n",
    "    \n",
    "    return clf, xxx_validate, pd.DataFrame(yy_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9389\n",
       "False    2491\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_4 = ['amount_tsh', 'population', 'funder_mod', 'district_code', 'basin', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type', 'management', 'payment', 'water_quality', 'quantity', 'source', 'waterpoint_type']\n",
    "categorical_variables = ['funder_mod', 'district_code', 'basin', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type', 'management', 'payment', 'water_quality', 'quantity', 'source', 'waterpoint_type']\n",
    "\n",
    "model, xxx_validate, yy_validate = create_randomforest_model(feature_set_4, categorical_variables)\n",
    "\n",
    "pred = model.predict(xxx_validate)\n",
    "yy_validate['pred'] = pred\n",
    "(yy_validate.pred == yy_validate.label).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9602\n",
       "False    2278\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_5 = ['amount_tsh', 'population', 'funder_mod', 'district_code', 'gps_height', 'region', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "categorical_variables = ['funder_mod', 'district_code', 'region', 'public_meeting', 'scheme_management', 'permit', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "\n",
    "model, xxx_validate, yy_validate = create_randomforest_model(feature_set_5, categorical_variables)\n",
    "\n",
    "pred = model.predict(xxx_validate)\n",
    "yy_validate['pred'] = pred\n",
    "(yy_validate.pred == yy_validate.label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "installer = x_train.funder.str.lower().value_counts()\n",
    "installer = funder[funder > 250]\n",
    "installer\n",
    "x_train['installer_mod'] = [i if i in installer else 'Unknown' for i in x_train.installer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     7671\n",
       "False    4209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to see if additional features are having an impact\n",
    "\n",
    "feature_set_6 = ['amount_tsh', 'population', 'waterpoint_type_group']\n",
    "categorical_variables = [ 'waterpoint_type_group']\n",
    "\n",
    "model, xxx_validate, yy_validate = create_randomforest_model(feature_set_6, categorical_variables)\n",
    "\n",
    "pred = model.predict(xxx_validate)\n",
    "yy_validate['pred'] = pred\n",
    "(yy_validate.pred == yy_validate.label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['funder_mod',\n",
       "                                                   'district_code', 'region',\n",
       "                                                   'public_meeting',\n",
       "                                                   'scheme_management',\n",
       "                                                   'permit',\n",
       "                                                   'extraction_type_group',\n",
       "                                                   'management_group',\n",
       "                                                   'payment_type',\n",
       "                                                   'quality_group',\n",
       "                                                   'quantity_group',\n",
       "                                                   'source_type',\n",
       "                                                   'waterpoint_type_group']),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['amount_tsh', 'population',\n",
       "                                                   'gps_height',\n",
       "                                                   'construction_year'])]))])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "feature_set_7 = ['amount_tsh', 'population', 'funder_mod', 'district_code', 'gps_height', 'region', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "numeric_features = ['amount_tsh', 'population', 'gps_height', 'construction_year']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_features = ['funder_mod', 'district_code', 'region', 'public_meeting', 'scheme_management', 'permit', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)\n",
    "                     ])\n",
    "\n",
    "xx_train, xx_test, yy_train, yy_test = train_test_split(x_train[feature_set_7], y_train, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf.fit(xx_train[feature_set_7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx_train = pd.DataFrame(clf.transform(xx_train).todense())\n",
    "xxx_test = pd.DataFrame(clf.transform(xx_test).todense())\n",
    "yyy_train = pd.DataFrame(yy_train['label'])\n",
    "yyy_test = pd.DataFrame(yy_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, concatenate, Input\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = Input(shape=xxx_train.shape[1], name='ip')\n",
    "x1 = Dense(250, activation='relu')(ip)\n",
    "x2 = Dense(100, activation='relu')(x1)\n",
    "x3 = Dense(50, activation='relu')(x2)\n",
    "x4 = Dense(10, activation='relu')(x3)\n",
    "output = Dense(1, activation='sigmoid')(x4)\n",
    "\n",
    "model = Model(inputs = ip, outputs=output)\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2970/2970 [==============================] - 3s 982us/step - loss: 0.4199 - accuracy: 0.7977\n",
      "Epoch 2/25\n",
      "2970/2970 [==============================] - 3s 928us/step - loss: 0.4110 - accuracy: 0.8022\n",
      "Epoch 3/25\n",
      "2970/2970 [==============================] - 3s 925us/step - loss: 0.4040 - accuracy: 0.8067\n",
      "Epoch 4/25\n",
      "2970/2970 [==============================] - 3s 970us/step - loss: 0.3987 - accuracy: 0.8085\n",
      "Epoch 5/25\n",
      "2970/2970 [==============================] - 3s 961us/step - loss: 0.3931 - accuracy: 0.8139\n",
      "Epoch 6/25\n",
      "2970/2970 [==============================] - 3s 941us/step - loss: 0.3880 - accuracy: 0.8160\n",
      "Epoch 7/25\n",
      "2970/2970 [==============================] - 3s 936us/step - loss: 0.3839 - accuracy: 0.8157\n",
      "Epoch 8/25\n",
      "2970/2970 [==============================] - 3s 963us/step - loss: 0.3796 - accuracy: 0.8204\n",
      "Epoch 9/25\n",
      "2970/2970 [==============================] - 3s 931us/step - loss: 0.3758 - accuracy: 0.8214\n",
      "Epoch 10/25\n",
      "2970/2970 [==============================] - 3s 941us/step - loss: 0.3717 - accuracy: 0.8229\n",
      "Epoch 11/25\n",
      "2970/2970 [==============================] - 3s 973us/step - loss: 0.3692 - accuracy: 0.8241\n",
      "Epoch 12/25\n",
      "2970/2970 [==============================] - 3s 978us/step - loss: 0.3650 - accuracy: 0.8270\n",
      "Epoch 13/25\n",
      "2970/2970 [==============================] - 3s 964us/step - loss: 0.3622 - accuracy: 0.8281\n",
      "Epoch 14/25\n",
      "2970/2970 [==============================] - 3s 953us/step - loss: 0.3598 - accuracy: 0.8303\n",
      "Epoch 15/25\n",
      "2970/2970 [==============================] - 3s 940us/step - loss: 0.3580 - accuracy: 0.8305\n",
      "Epoch 16/25\n",
      "2970/2970 [==============================] - 3s 991us/step - loss: 0.3553 - accuracy: 0.8318\n",
      "Epoch 17/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3528 - accuracy: 0.8334\n",
      "Epoch 18/25\n",
      "2970/2970 [==============================] - 3s 959us/step - loss: 0.3512 - accuracy: 0.8335\n",
      "Epoch 19/25\n",
      "2970/2970 [==============================] - 3s 947us/step - loss: 0.3494 - accuracy: 0.8353\n",
      "Epoch 20/25\n",
      "2970/2970 [==============================] - 3s 948us/step - loss: 0.3470 - accuracy: 0.8356\n",
      "Epoch 21/25\n",
      "2970/2970 [==============================] - 3s 949us/step - loss: 0.3465 - accuracy: 0.8339\n",
      "Epoch 22/25\n",
      "2970/2970 [==============================] - 3s 951us/step - loss: 0.3445 - accuracy: 0.8368\n",
      "Epoch 23/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3431 - accuracy: 0.8364\n",
      "Epoch 24/25\n",
      "2970/2970 [==============================] - 3s 982us/step - loss: 0.3414 - accuracy: 0.8366\n",
      "Epoch 25/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3401 - accuracy: 0.8387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb7a2cb890>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xxx_train, yyy_train, epochs=25, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_raw = model.predict(xxx_test).flatten()\n",
    "pred = [round(i) for i in pred_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_test['pred'] = pred\n",
    "yyy_test['correct'] = (yyy_test.label == yyy_test.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9450\n",
       "False    2430\n",
       "Name: correct, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_test.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = sample(list(x_train.id), len(x_train)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['funder_mod',\n",
       "                                                   'district_code', 'region',\n",
       "                                                   'public_meeting',\n",
       "                                                   'scheme_management',\n",
       "                                                   'permit',\n",
       "                                                   'extraction_type_group',\n",
       "                                                   'management_group',\n",
       "                                                   'payment_type',\n",
       "                                                   'quality_group',\n",
       "                                                   'quantity_group',\n",
       "                                                   'source_type',\n",
       "                                                   'waterpoint_type_group']),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['amount_tsh', 'population',\n",
       "                                                   'gps_height',\n",
       "                                                   'construction_year'])]))])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set_8 = ['amount_tsh', 'population', 'funder_mod', 'district_code', 'gps_height', 'region', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "numeric_features = ['amount_tsh', 'population', 'gps_height', 'construction_year']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_features = ['funder_mod', 'district_code', 'region', 'public_meeting', 'scheme_management', 'permit', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)\n",
    "                     ])\n",
    "xx_train, xx_test, yy_train, yy_test = train_test_split(x_train[feature_set_7], y_train, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf.fit(xx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx_train = pd.DataFrame(clf.transform(xx_train).todense())\n",
    "xxx_test = pd.DataFrame(clf.transform(xx_test).todense())\n",
    "yyy_train = pd.DataFrame(yy_train['label'])\n",
    "yyy_test = pd.DataFrame(yy_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateekagarwal2/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_model = HistGradientBoostingClassifier()\n",
    "grad_boost_model.fit(xxx_train, yyy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateekagarwal2/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(xxx_train, yyy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2970/2970 [==============================] - 3s 992us/step - loss: 0.4874 - accuracy: 0.7569\n",
      "Epoch 2/25\n",
      "2970/2970 [==============================] - 3s 957us/step - loss: 0.4476 - accuracy: 0.7829\n",
      "Epoch 3/25\n",
      "2970/2970 [==============================] - 3s 951us/step - loss: 0.4310 - accuracy: 0.7904\n",
      "Epoch 4/25\n",
      "2970/2970 [==============================] - 3s 958us/step - loss: 0.4202 - accuracy: 0.7974\n",
      "Epoch 5/25\n",
      "2970/2970 [==============================] - 3s 953us/step - loss: 0.4110 - accuracy: 0.8033\n",
      "Epoch 6/25\n",
      "2970/2970 [==============================] - 3s 952us/step - loss: 0.4050 - accuracy: 0.8077\n",
      "Epoch 7/25\n",
      "2970/2970 [==============================] - 3s 958us/step - loss: 0.3992 - accuracy: 0.8116\n",
      "Epoch 8/25\n",
      "2970/2970 [==============================] - 3s 954us/step - loss: 0.3942 - accuracy: 0.8129\n",
      "Epoch 9/25\n",
      "2970/2970 [==============================] - 3s 972us/step - loss: 0.3885 - accuracy: 0.8152\n",
      "Epoch 10/25\n",
      "2970/2970 [==============================] - 3s 957us/step - loss: 0.3856 - accuracy: 0.8176\n",
      "Epoch 11/25\n",
      "2970/2970 [==============================] - 3s 953us/step - loss: 0.3798 - accuracy: 0.8201\n",
      "Epoch 12/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3764 - accuracy: 0.8221\n",
      "Epoch 13/25\n",
      "2970/2970 [==============================] - 3s 976us/step - loss: 0.3727 - accuracy: 0.8230\n",
      "Epoch 14/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3700 - accuracy: 0.8254\n",
      "Epoch 15/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3663 - accuracy: 0.8269\n",
      "Epoch 16/25\n",
      "2970/2970 [==============================] - 3s 978us/step - loss: 0.3633 - accuracy: 0.8285\n",
      "Epoch 17/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3613 - accuracy: 0.8281\n",
      "Epoch 18/25\n",
      "2970/2970 [==============================] - 4s 1ms/step - loss: 0.3587 - accuracy: 0.8307\n",
      "Epoch 19/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3565 - accuracy: 0.8314\n",
      "Epoch 20/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3545 - accuracy: 0.8311\n",
      "Epoch 21/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3528 - accuracy: 0.8333\n",
      "Epoch 22/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3511 - accuracy: 0.8331\n",
      "Epoch 23/25\n",
      "2970/2970 [==============================] - 3s 987us/step - loss: 0.3490 - accuracy: 0.8341\n",
      "Epoch 24/25\n",
      "2970/2970 [==============================] - 3s 996us/step - loss: 0.3479 - accuracy: 0.8355\n",
      "Epoch 25/25\n",
      "2970/2970 [==============================] - 3s 984us/step - loss: 0.3472 - accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb79517290>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = Input(shape=xxx_train.shape[1], name='ip')\n",
    "x1 = Dense(250, activation='relu')(ip)\n",
    "x2 = Dense(100, activation='relu')(x1)\n",
    "x3 = Dense(50, activation='relu')(x2)\n",
    "x4 = Dense(10, activation='relu')(x3)\n",
    "output = Dense(1, activation='sigmoid')(x4)\n",
    "\n",
    "nn_model = Model(inputs = ip, outputs=output)\n",
    "nn_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.fit(xxx_train, yyy_train, epochs=25, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_pred = grad_boost_model.predict(xxx_test)\n",
    "random_forest_pred = random_forest_model.predict(xxx_test)\n",
    "nn_pred = nn_model.predict(xxx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_test['gb_pred'] = grad_boost_pred\n",
    "yyy_test['rf_pred'] = random_forest_pred\n",
    "yyy_test['nn_pred_raw'] = nn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_test['nn_pred'] = round(yyy_test.nn_pred_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>gb_pred</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>nn_pred_raw</th>\n",
       "      <th>nn_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11524</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.568859</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16731</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48776</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526282</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23300</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901758</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25270</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777077</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37939</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636074</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35407</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185051</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50590</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37956</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11880 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  gb_pred  rf_pred  nn_pred_raw  nn_pred\n",
       "11524      1        1        1     0.568859      1.0\n",
       "16731      0        0        0     0.039152      0.0\n",
       "48776      0        1        1     0.526282      1.0\n",
       "23300      1        1        1     0.901758      1.0\n",
       "25270      0        1        0     0.130993      0.0\n",
       "...      ...      ...      ...          ...      ...\n",
       "1572       1        1        1     0.777077      1.0\n",
       "37939      0        1        1     0.636074      1.0\n",
       "35407      0        0        0     0.185051      0.0\n",
       "50590      0        0        0     0.017304      0.0\n",
       "37956      0        1        1     0.500675      1.0\n",
       "\n",
       "[11880 rows x 5 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_test[\"sum\"] = yyy_test.gb_pred + yyy_test.rf_pred + yyy_test.nn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_test[\"consensus\"] = yyy_test['sum'].apply(lambda x: 1 if x in [2, 3] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9604\n",
       "False    2276\n",
       "dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(yyy_test.consensus == yyy_test.label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9620\n",
       "False    2260\n",
       "dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(yyy_test.rf_pred == yyy_test.label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
