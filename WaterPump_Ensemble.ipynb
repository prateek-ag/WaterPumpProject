{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('WaterPumpData/features_train.csv')\n",
    "y_train = pd.read_csv('WaterPumpData/labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['label'] = y_train.status_group.apply(lambda x: 1 if x == 'functional' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "funder = x_train.funder.str.lower().value_counts()\n",
    "funder = funder[funder > 250]\n",
    "x_train['funder_mod'] = [i if i in funder else 'Unknown' for i in x_train.funder]\n",
    "\n",
    "installer = x_train.funder.str.lower().value_counts()\n",
    "installer = funder[funder > 250]\n",
    "installer\n",
    "x_train['installer_mod'] = [i if i in installer else 'Unknown' for i in x_train.installer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample\n",
    "\n",
    "validation_set = sample(list(x_train.id), len(x_train)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train = x_train.loc[~x_train.id.isin(validation_set)]\n",
    "xx_validate = x_train.loc[x_train.id.isin(validation_set)]\n",
    "yy_train = y_train.loc[~y_train.id.isin(validation_set)].label\n",
    "yy_validate = y_train.loc[y_train.id.isin(validation_set)].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def pipeline(feature_set, numeric_set):\n",
    "    numeric_features = numeric_set\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_features =  [i for i in feature_set if i not in numeric_set]\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "        ])\n",
    "\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor)\n",
    "                         ])\n",
    "\n",
    "    clf.fit(xx_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_8 = ['amount_tsh', 'population', 'funder_mod', 'district_code', 'gps_height', 'region', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type_group', 'management_group', 'payment_type', 'quality_group', 'quantity_group', 'source_type', 'waterpoint_type_group']\n",
    "numeric_features = ['amount_tsh', 'population', 'gps_height', 'construction_year']\n",
    "clf = pipeline(feature_set_8, numeric_features)\n",
    "\n",
    "xxx_train = pd.DataFrame(clf.transform(xx_train).todense())\n",
    "xxx_validate = pd.DataFrame(clf.transform(xx_validate).todense())\n",
    "yyy_train = pd.DataFrame(yy_train)\n",
    "yyy_validate = pd.DataFrame(yy_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "def create_gradientbooster_model(feature_set, cat_var):\n",
    "    clf = HistGradientBoostingClassifier()\n",
    "    clf.fit(xxx_train, yy_train)\n",
    "    \n",
    "    return clf, xxx_validate, pd.DataFrame(yy_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def create_randomforest_model(feature_set, cat_var):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(xxx_train, yyy_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateekagarwal2/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_boost_model = HistGradientBoostingClassifier()\n",
    "grad_boost_model.fit(xxx_train, yyy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prateekagarwal2/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(xxx_train, yyy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2970/2970 [==============================] - 3s 910us/step - loss: 0.4885 - accuracy: 0.7554\n",
      "Epoch 2/25\n",
      "2970/2970 [==============================] - 3s 905us/step - loss: 0.4481 - accuracy: 0.7822\n",
      "Epoch 3/25\n",
      "2970/2970 [==============================] - 3s 895us/step - loss: 0.4302 - accuracy: 0.7922\n",
      "Epoch 4/25\n",
      "2970/2970 [==============================] - 3s 898us/step - loss: 0.4191 - accuracy: 0.7987\n",
      "Epoch 5/25\n",
      "2970/2970 [==============================] - 3s 897us/step - loss: 0.4105 - accuracy: 0.8023\n",
      "Epoch 6/25\n",
      "2970/2970 [==============================] - 3s 997us/step - loss: 0.4023 - accuracy: 0.8080\n",
      "Epoch 7/25\n",
      "2970/2970 [==============================] - 3s 920us/step - loss: 0.3957 - accuracy: 0.8116\n",
      "Epoch 8/25\n",
      "2970/2970 [==============================] - 3s 937us/step - loss: 0.3898 - accuracy: 0.8145\n",
      "Epoch 9/25\n",
      "2970/2970 [==============================] - 3s 908us/step - loss: 0.3836 - accuracy: 0.8186\n",
      "Epoch 10/25\n",
      "2970/2970 [==============================] - 3s 911us/step - loss: 0.3784 - accuracy: 0.8204\n",
      "Epoch 11/25\n",
      "2970/2970 [==============================] - 3s 907us/step - loss: 0.3738 - accuracy: 0.8227\n",
      "Epoch 12/25\n",
      "2970/2970 [==============================] - 3s 917us/step - loss: 0.3689 - accuracy: 0.8248\n",
      "Epoch 13/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3651 - accuracy: 0.8266\n",
      "Epoch 14/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3618 - accuracy: 0.8275\n",
      "Epoch 15/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3574 - accuracy: 0.8300\n",
      "Epoch 16/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3539 - accuracy: 0.8325\n",
      "Epoch 17/25\n",
      "2970/2970 [==============================] - 3s 1ms/step - loss: 0.3506 - accuracy: 0.8335\n",
      "Epoch 18/25\n",
      "2970/2970 [==============================] - 3s 927us/step - loss: 0.3483 - accuracy: 0.8348\n",
      "Epoch 19/25\n",
      "2970/2970 [==============================] - 3s 923us/step - loss: 0.3462 - accuracy: 0.8354\n",
      "Epoch 20/25\n",
      "2970/2970 [==============================] - 3s 924us/step - loss: 0.3427 - accuracy: 0.8378\n",
      "Epoch 21/25\n",
      "2970/2970 [==============================] - 3s 945us/step - loss: 0.3410 - accuracy: 0.8374\n",
      "Epoch 22/25\n",
      "2970/2970 [==============================] - 3s 977us/step - loss: 0.3381 - accuracy: 0.8390\n",
      "Epoch 23/25\n",
      "2970/2970 [==============================] - 3s 982us/step - loss: 0.3364 - accuracy: 0.8410\n",
      "Epoch 24/25\n",
      "2970/2970 [==============================] - 4s 1ms/step - loss: 0.3329 - accuracy: 0.8412\n",
      "Epoch 25/25\n",
      "2970/2970 [==============================] - 4s 1ms/step - loss: 0.3317 - accuracy: 0.8421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb6a7f30050>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, concatenate, Input\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "ip = Input(shape=xxx_train.shape[1], name='ip')\n",
    "x1 = Dense(250, activation='relu')(ip)\n",
    "x2 = Dense(100, activation='relu')(x1)\n",
    "x3 = Dense(50, activation='relu')(x2)\n",
    "x4 = Dense(10, activation='relu')(x3)\n",
    "output = Dense(1, activation='sigmoid')(x4)\n",
    "\n",
    "nn_model = Model(inputs = ip, outputs=output)\n",
    "nn_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.fit(xxx_train, yyy_train, epochs=25, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_pred = grad_boost_model.predict(xxx_validate)\n",
    "random_forest_pred = random_forest_model.predict(xxx_validate)\n",
    "nn_pred = nn_model.predict(xxx_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_validate['gb_pred'] = grad_boost_pred\n",
    "yyy_validate['rf_pred'] = random_forest_pred\n",
    "yyy_validate['nn_pred_raw'] = nn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_validate['nn_pred'] = round(yyy_validate.nn_pred_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_validate[\"sum\"] = yyy_validate.gb_pred + yyy_validate.rf_pred + yyy_validate.nn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_validate[\"consensus\"] = yyy_validate['sum'].apply(lambda x: 1 if x in [2, 3] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9639\n",
       "False    2241\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(yyy_validate.consensus == yyy_validate.label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     9545\n",
       "False    2335\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(yyy_validate.rf_pred == yyy_validate.label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
